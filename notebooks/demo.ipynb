{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rr0NLcgw_ojs"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "from src.preprocessing import (\n",
        "    split_features_target,\n",
        "    split_data,\n",
        "    SplitConfig\n",
        ")\n",
        "from src.data import DataLoader\n",
        "from src.model import build_model_pipeline\n",
        "from src.eval import (\n",
        "    validate_model,\n",
        "    run_grid_search\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ONwHZhhfA8-j"
      },
      "outputs": [],
      "source": [
        "PARAM_GRID = {\n",
        "    \"elasticnet\": {\n",
        "        \"model__alpha\": [0.001, 0.01, 0.1, 1.0, 10.0],\n",
        "        \"model__l1_ratio\": [0.1, 0.5, 0.9],\n",
        "        \"model__max_iter\": [1000, 2000, 5000, 10000],\n",
        "    },\n",
        "    \"random_forest\": {\n",
        "        \"model__n_estimators\": [100, 200, 300, 400, 500],\n",
        "        \"model__max_depth\": [None, 10, 20, 30, 40],\n",
        "        \"model__min_samples_split\": [2, 5, 10, 20],\n",
        "    },\n",
        "    \"xgboost\": {\n",
        "        \"model__n_estimators\": [100, 300, 500, 1000],\n",
        "        \"model__learning_rate\": [0.01, 0.05, 0.1, 0.5, 1.0],\n",
        "        \"model__max_depth\": [3, 6, 9, 12],\n",
        "        \"model__subsample\": [0.2, 0.6, 0.8, 1.0],\n",
        "        \"model__colsample_bytree\": [0.2, 0.6, 0.8, 1.0],\n",
        "    },\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "eExXZY17A-7b"
      },
      "outputs": [],
      "source": [
        "# Configuration\n",
        "dataset = \"house_prices\"  # OpenML dataset name\n",
        "target_col = \"SalePrice\"\n",
        "split_cfg = SplitConfig(val_size=0.3, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0CLMGL0XBGfa"
      },
      "outputs": [],
      "source": [
        "# 1. model and data loading\n",
        "model_names = [\"elasticnet\", \"random_forest\", \"xgboost\"]\n",
        "df = DataLoader.load_data_from_openml(dataset_name=dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TIhcg75YBJhy"
      },
      "outputs": [],
      "source": [
        "# 2. data splitting\n",
        "X, y = split_features_target(df, target_col=target_col)\n",
        "train, val, test = split_data(X, y, cfg=split_cfg) # df[X, y]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Ejwe2G8CBdWc"
      },
      "outputs": [],
      "source": [
        "# Tally scores\n",
        "scores_basic = {\n",
        "    \"validation\": {},\n",
        "    \"evaluation\": {}\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMq71x_pBPpK",
        "outputId": "7dc16ee3-a9c2-4a42-c09f-29dc4dce02d1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training models: 100%|██████████| 3/3 [00:28<00:00,  9.62s/it]\n"
          ]
        }
      ],
      "source": [
        "# 3.1 models pipeline\n",
        "for model_name in tqdm(model_names, desc=\"Training models\"):\n",
        "    pipeline = build_model_pipeline(model_name, train[0])\n",
        "\n",
        "    # 4.1 model training\n",
        "    pipeline.fit(train[0], train[1])\n",
        "\n",
        "    # 5.1 model evaluation on validation set\n",
        "    val_score = validate_model(pipeline, val[0], val[1], cv=5)\n",
        "\n",
        "    # 6.1 final test evaluation\n",
        "    eval_score = pipeline.score(test[0], test[1])\n",
        "\n",
        "    # 7.1 save scores\n",
        "    scores_basic[\"validation\"][model_name] = val_score\n",
        "    scores_basic[\"evaluation\"][model_name] = eval_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsF_aLnZBRl1",
        "outputId": "ba0e7110-7aee-4873-acfe-67c763b88fe6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "========================================\n",
            "Final Evaluation Scores:\n",
            "elasticnet: R^2 = 0.8795\n",
            "random_forest: R^2 = 0.8780\n",
            "xgboost: R^2 = 0.8919\n",
            "========================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 8.1 final scores output\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"Final Evaluation Scores:\")\n",
        "for model_name, score in scores_basic[\"evaluation\"].items():\n",
        "    print(f\"{model_name}: R^2 = {score:.4f}\")\n",
        "print(\"=\"*40 + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Xj2FEIJ8BTx7"
      },
      "outputs": [],
      "source": [
        "# Tally scores\n",
        "scores_optim = {\n",
        "    \"validation\": {},\n",
        "    \"evaluation\": {}\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9AEBsAWBoMa",
        "outputId": "3d12b4d6-eff2-4813-f0bf-53544a201a94"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Optimizing models:  33%|███▎      | 1/3 [01:05<02:11, 65.61s/it]"
          ]
        }
      ],
      "source": [
        "### ---------- Optimized Run (w/ GridSearch) ---------- ###\n",
        "\n",
        "# 3.2 models pipeline\n",
        "for model_name in tqdm(model_names, desc=\"Optimizing models\"):\n",
        "  pipeline = build_model_pipeline(model_name, train[0])\n",
        "\n",
        "  # 4.2 model training with GridSearchCV\n",
        "  grid_search = run_grid_search(\n",
        "      model_name, train[0], train[1],\n",
        "      param_grid=PARAM_GRID.get(model_name, None),\n",
        "      cv=5, scoring=\"neg_mean_squared_error\"\n",
        "  )\n",
        "\n",
        "  # 5.2 model evaluation on validation set\n",
        "  val_score = validate_model(grid_search.best_estimator_, val[0], val[1], cv=5)\n",
        "\n",
        "  # 6.2 final test evaluation\n",
        "  eval_score = grid_search.best_estimator_.score(test[0], test[1])\n",
        "\n",
        "  # 7.2 save scores\n",
        "  scores_optim[\"validation\"][model_name] = val_score\n",
        "  scores_optim[\"evaluation\"][model_name] = eval_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8M-TCcNBuYR"
      },
      "outputs": [],
      "source": [
        "# 8.2 final scores output\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"Final Evaluation Scores (Optimized):\")\n",
        "for model_name, score in scores_optim[\"evaluation\"].items():\n",
        "    print(f\"{model_name}: R^2 = {score:.4f}\")\n",
        "print(\"=\"*40 + \"\\n\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
